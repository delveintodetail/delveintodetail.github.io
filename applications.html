<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Applications</title>
</head>
<div align="center">
<div style="width:950px; text-align:left;">



<h2>Texture Classification</h2>
In our experiment, we use 3, 40, 46 training samples for Brodatz, CUReT and KTH-TIPS individually. We directly extract PRI-CoLBP on the texture images and the feature dimension is 1180. We use one-vs-the-rest kernel SVM Classifier.
<p>&nbsp;</p>
<right>
<img src="images/texture.jpg" width="400" height="350" alt="Texture" />
</right>

<right>
<img src="images/texture_result.jpg" width="400" height="350" alt="Texture" />
</right>
<p> </p>
<p>&nbsp;</p>
	PRI-CoLBP is designed to capture spatial co-occurrence of LBP. For the table,  we can find that PRI-CoLBP significantly outperforms multi-scale LBP.  Meanwhile, it also exceed some state-of-the-art methods.
Although extracting multi-scale and multi-orientation PRI-CoLBP could further boost the performance, we just demonstrate the effectiveness of the PRI-CoLBP.
It should be noted that the PRI-CoLBP is computationally efficient. It takes about 0.031s to process an 200*200 image.
 

<font color="#669933">
<br></br>
<h4>References</h4>
[35] H. Nguyen, R. Fablet, and J. Boucher, “Visual textures as realizations of multivariate log-gaussian cox processes,” CVPR, 2011.
<br>[8] J. Zhang, M. Marszalek, S. Lazebnik, and C. Schmid, “Local features and kernels for classiﬁcation of texture and object categories: A comprehensive study,” CVPR, 2007.</br>
<br>[33] M. Varma and A. Zisserman, “A statistical approach to material classiﬁcation using image patch exemplars,” PAMI, 2008.</br>
<br>[34] B. Caputo, E. Hayman, M. Fritz, and J. Eklundh, “Classifying materials in the real world,” Image and Vision Computing, 2010.</br>
<br>[6] S. Lazebnik, C. Schmid, and J. Ponce, “A sparse texture representation using local afﬁne regions,” PAMI, 2005.</br>
<br>[9] T. Ojala, M. Pietik¨ ainen, and T. M¨ aenp¨ a¨ a, “Multiresolution gray-scale and rotation invariant texture classiﬁcation with local binary patterns,” PAMI, 2002.</br>
<p>&nbsp;</p>
<p>&nbsp;</p>
</font>



<h2>Material Recognition</h2>
The Flickr Material Database is chanllenging. FMD contains 10 classes which consist of fabric, foliage, glass, leather, metal, paper, plastic, stone, water and wood. Each category contains 100 images, where 50 in all 100 images is close-up views and the rest 50 are of views at object-scale. We extract PRI-CoLBP on the forground region provided by original authors. We use 50 training samples and the rest for test.
<p>&nbsp;</p>
<right>
<img src="images/material.jpg" width="400" height="280" alt="Material" />
</right>
<right>
<img src="images/FMD_result.jpg" width="400" height="300" alt="Material" />
</right>
<p>&nbsp;</p>

For single feature, PRI-CoLBP greatly outperforms bag of SIFT and kernel descriptor. Meanwhile, it also exceed the combinations of four kernel descriptors. It should be pointed out that SVM classifier works better than the augmented Latent Dirichlet Allocation (aLDA) method.
<br></br>

<font color="#669933">
<br> </br>
<h4>References</h4>
[22] C. Liu, L. Sharan, E. Adelson, and R. Rosenholtz, “Exploring features in a bayesian framework for material recognition,” CVPR, 2010.
<br> </br>
[37] D. Hu and L. Bo, “Toward robust material recognition for everyday objects,” BMVC, 2011.
<br> </br>
</font>
<p>&nbsp;</p>
<p>&nbsp;</p>


<h2>Flower Recognition</h2>

The table shows a comparison between recent publications on the Oxford Flower 102 dataset. To failly compare our feature with new published work [27], we use the same classifier (Adaptive kernel approximation and linear SVM) with them. The mean per-class percent accuracy is applied. 


<p>&nbsp;</p>
<center>
  <img src="images/flower.jpg" width="700" height="250" alt="Flower" />
</center>
<center>
  <img src="images/flower_result.jpg" width="600" height="350" alt="Flower" />
</center>
<p>&nbsp;</p>
First of all, we want to thank Andrew Zisserman's group for some valuable discussion. The work is firstly motivated by working on flower recognition project. Their works on flower segmentation and recognition are great.

<br> </br>
For single feature, PRI-CoLBP outperforms its competitors, such as MSLBP, CoHED, Bag-of-foreground SIFT, color histogram. For feature combination, it also improves the work of Nilsback et al. and Chai's work.

<br> </br>
<font color="#669933">
<br> </br>
<h4>References</h4>
[4] S. Ito and S. Kubota, “Object classiﬁcation using heterogeneous co-occurrence features,” ECCV, 2010.
<br> </br>
[5] C. Kanan and G. Cottrell, “Robust classiﬁcation of objects, faces, and ﬂowers using natural image statistics,” CVPR, 2010.
<br> </br>
[23] M. Nilsback and A. Zisserman, “Automated ﬂower classiﬁcation over a large number of classes,” ICVGIP, 2008.
<br> </br>
[26] M. Nilsback, “An automatic visual ﬂora - segmentation and classiﬁcation of ﬂowers images,” in PhD thesis, University of Oxford.
<br> </br>
[27] Y. Chai, V. Lempitsky, and A. Zisserman, “Bicos: A bi-level co-segmentation method for image classiﬁcation,” ICCV, 2011.
<br> </br>
[42] X. Yuan and S. Yan, “Visual classiﬁcation with multi-task joint sparse representation,” CVPR, 2010.
<br> </br>
</font>
<p>&nbsp;</p>
<p>&nbsp;</p>



<h2>Leaf Recognition</h2>
Using adaptive threshold segmentation, we can automatically segment out the flower from white backgournd, and extract the PRI-CoLBP on the foreground region. Following the standard configuration, we use 25 training samples and the rest for test.
<p>&nbsp;</p>
<center>
  <img src="images/leaf.jpg" width="700" height="250" alt="Leaf" />
</center>
<center>
  <img src="images/leaf_result.jpg" width="800" height="250" alt="Leaf" />
</center>
<p>&nbsp;</p>

Leaf recognition problem is first dealed with as a shape recognition problem. We conclude our PRI-CoLBP and CENTRIST [45] as a texture-based method. The texture-based could well handle partial loss. 

<font color="#669933">
<br> </br>
<h4>References</h4>
[24] O. S¨ oderkvist, “Computer vision classiﬁcation of leaves from swedish trees,” Master’s Thesis, Linkoping University, 2001.
<br> </br>
[45] J. Wu and J. Rehg, “Centrist: A visual descriptor for scene categorization,” PAMI, 2011.
<br> </br>
[46] H. Ling and D. Jacobs, “Shape classiﬁcation using the inner-distance,” PAMI, 2007
<br> </br>
[47] P. Felzenszwalb and J. Schwartz, “Hierarchical matching of deformable shapes,” in CVPR, 2007.
<br> </br>
</font>
<p>&nbsp;</p>
<p>&nbsp;</p>


<h2>Food Recognition</h2>
In this paper, we totally follow the experimental setup of [15]. We run experiments on 61 categories and 7 major categories individually.
<p>&nbsp;</p>
<center>
  <img src="images/food.jpg" width="800" height="200" alt="Food" />
</center>
<center>
  <img src="images/food_result.jpg" width="800" height="200" alt="Food" />
</center>
<center>
  <img src="images/food_result2.jpg" width="600" height="450" alt="Food" />
</center>
<p>&nbsp;</p>

Only using gray images, our method greatly outperforms the work of [15]. Using color images like [15], we further improves our feature.  The dimension of PRI-CoLBP on gray image is 1180, and the dimension of color PRI-CoLBP is 3560.  



<font color="#669933">
<br> </br>
<h4>References</h4>
[15] S. Yang, M. Chen, D. Pomerleau, and R. Sukthankar, “Food recognition using statistics of pairwise local features,” CVPR, 2010.
<br> </br>
[48] J. Shotton, M. Johnson, and R. Cipolla, “Semantic texton forests for image categorization and segmentation,” CVPR, 2008.
<br> </br>
</font>
<p>&nbsp;</p>
<p>&nbsp;</p>



<h2>Scene Classification</h2>
I will add the content later.
<p>&nbsp;</p>
<center>
  <p><img src="images/scene.jpg" width="500" height="300" alt="Scene" /></p>  
</center>
<center>
  <p><img src="images/scene_result.jpg" width="650" height="200" alt="Scene" /></p>  
</center>
<p>&nbsp;</p>
<p>&nbsp;</p>



<font color="#669933">
<br> </br>
<h4>References</h4>
[14] N. Rasiwasia and N. Vasconcelos, “Holistic context modeling using semantic co-occurrences,” in CVPR, 2009.
<br> </br>
[25] S. Lazebnik, C. Schmid, and J. Ponce, “Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories,” CVPR, 2006.
<br> </br>
[43] A. Oliva and A. Torralba, “Modeling the shape of the scene: A holistic representation of the spatial envelope,” IJCV, 2001.
<br> </br>
[45] J. Wu and J. Rehg, “Centrist: A visual descriptor for scene categorization,” PAMI, 2011.
<br> </br>
[50] J. C. van Gemert, C. J. Veenman, A. W. M. Smeulders, and J. M. Geusebroek, “Visual word ambiguity,” PAMI, 2009.
<br> </br>
</font>



</div>
</div>
<body>
</body>
</html>
